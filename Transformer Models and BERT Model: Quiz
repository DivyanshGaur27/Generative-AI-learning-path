What are the two sublayers of each encoder in a Transformer model?
=>Self-attention and feedforward

What does fine-tuning a BERT model mean?
=>Training the model and updating the pre-trained weights on a specific task by using labeled data

What kind of transformer model is BERT?
=>Encoder-only model.

What are the three different embeddings that are generated from an input sentence in a Transformer model?
=>Token, segment, and position embeddings

What is the attention mechanism?
=> A way of determining the importance of each word in a sentence for the translation of another sentence

What is a transformer model?
=> A deep learning model that uses self-attention to learn relationships between different parts of a sequence.

What is the name of the language modeling technique that is used in Bidirectional Encoder Representations from Transformers (BERT)?
=> Transformer

BERT is a transformer model that was developed by Google in 2018. What is BERT used for?
=> It is used to solve many natural language processing tasks, such as question answering, text classification, and natural language inference.
